{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Eq_QfGIGXC_"
      },
      "source": [
        "### **Búsqueda y Minería de Información 2021-22**\n",
        "### Universidad Autónoma de Madrid, Escuela Politécnica Superior\n",
        "### Grado en Ingeniería Informática, 4º curso\n",
        "# **Sistemas de recomendación y análisis de redes sociales**\n",
        "\n",
        "Fechas:\n",
        "\n",
        "* Comienzo: lunes 28 / martes 29 de marzo\n",
        "* Entrega: lunes 9 de mayo, 23:59"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYT0Qlrnoy7l"
      },
      "source": [
        "# Introducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDFY_K6_pA_J"
      },
      "source": [
        "## Objetivos\n",
        "\n",
        "Esta práctica reúne dos objetivos: por una parte implementar y evaluar sistemas de recomendación, y por otra, implementar funcionalidades de análisis de redes sociales. \n",
        "\n",
        "Respecto al primer objetivo, se desarrollarán:\n",
        "\n",
        "* Algoritmos de recomendación basada en filtrado colaborativo.\n",
        "* Métricas de evaluación de sistemas de recomendación.\n",
        "\n",
        "Y para el segundo, se implementarán:\n",
        "\n",
        "* Métricas que se utilizan en el análisis de redes sociales.\n",
        "* Otras funcionalidades a elección opcional del estudiante, tales como más métricas, la detección de comunidades, la generación aleatoria de redes sociales, o la recomendación de contactos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPjq_DVVpDEL"
      },
      "source": [
        "## Material proporcionado\n",
        "\n",
        "Se proporcionan (tanto en el curso de Moodle como con enlaces dentro de este documento) software y datos para la realización de la práctica, que se divide en dos bloques:\n",
        "\n",
        "**Bloque I – Sistemas de recomendación**\n",
        "\n",
        "* Un esqueleto de clases y funciones donde el estudiante desarrollará sus implementaciones. De modo similar a las prácticas anteriores, se proporciona una función principal **main_recsys** que deberá funcionar con el código a implementar por el estudiante.\n",
        "* Dos conjuntos de datos que incluyen ratings asignados por usuarios a películas: un conjunto pequeño de datos ficticios, y otro conjunto de datos reales disponibles en la Web de MovieLens.\n",
        "  - Conjunto pequeño de prueba <ins>toy-ratings.dat</ins> con datos ficticios de ratings, así como un split manual fijo de estos datos en <ins>toy-train.dat</ins> y <ins>toy-test.dat</ins>.\n",
        "  - Conjunto de datos real en la Web de [MovieLens](https://grouplens.org/datasets/movielens/latest), disponible en *ml-latest-small.zip*. De los archivos disponibles, se utilizará sólamente <ins>ratings.csv</ins>.\n",
        "* Un documento de texto <ins>recsys-output.txt</ins> con la correspondiente salida estándar que deberá producir la ejecución de la función **main_recsys**.\n",
        "\n",
        "**Bloque II – Análisis de redes sociales**\n",
        "\n",
        "* Un esqueleto de clases y funciones donde el estudiante desarrollará sus implementaciones. De modo similar a las prácticas anteriores, se proporciona una función principal **main_sna** que deberá funcionar con el código a implementar por el estudiante.\n",
        "* Redes sociales de prueba:\n",
        "  - Tres redes pequeñas de prueba.\n",
        "  - Redes reales: la red disponible en [SNAP (facebook_combined)](https://snap.stanford.edu/data/egonets-Facebook.html), y <ins>twitter.csv</ins> obtenida mediante una descarga de Twitter (unos 10 mil usuarios con medio millón de relaciones follow).\n",
        "  - Al conjunto de redes de prueba, el estudiante añadirá dos redes más, simuladas, en el ejercicio 5.\n",
        "* Un documento de texto <ins>sna-output.txt</ins> con la correspondiente salida estándar que deberá producir la ejecución de la función **main_sna**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKBXprvhpqQr"
      },
      "source": [
        "## Calificación\n",
        "\n",
        "Esta práctica se calificará con una puntuación de 0 a 10 atendiendo a las puntuaciones individuales de ejercicios y apartados dadas en el enunciado. El peso de la nota de esta práctica en la calificación final de prácticas es del **40%**.\n",
        "\n",
        "La calificación se basará en el **número** de ejercicios realizados y la **calidad** de los mismos. La puntuación que se indica en cada apartado es orientativa, en principio se aplicará tal cual se refleja pero podrá matizarse por criterios de buen sentido si se da el caso.\n",
        "\n",
        "Para dar por válida la realización de un ejercicio, el código deberá funcionar (a la primera) integrado con las clases que se facilitan. El profesor comprobará este aspecto combinando las clases entregadas por el estudiante en los programas main facilitados, así como en otros adicionales.\n",
        "\n",
        "La corrección de las implementaciones se observará por la **coherencia de los resultados** (por ejemplo, las métricas sobre los algoritmos de recomendación), y se valorará la eficiencia en tiempo de ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfMu2CuGprtk"
      },
      "source": [
        "## Entrega\n",
        "\n",
        "La entrega consistirá en un único fichero tipo *notebook* donde se incluirán todas las **implementaciones** solicitadas en cada ejercicio, así como una explicación de cada uno a modo de **memoria**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--pSxv2vpvUg"
      },
      "source": [
        "## Indicaciones\n",
        "\n",
        "La realización de los ejercicios conducirá en muchos casos a la implementación de funciones y/o clases adicionales a las que se indican en el enunciado. Algunas vendrán dadas por su aparición en las propias funciones main, y otras por conveniencia a criterio del estudiante.\n",
        "\n",
        "Igual que en prácticas anteriores, no deberán editarse las funciones **main_recsys** y **main_sna**. Estos programas deberán ejecutar sin errores \"a la primera\" con el código entregado por el estudiante (naturalmente con salvedad de los ejercicios que no se hayan implementado). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3jRLNZmpEk_"
      },
      "source": [
        "# Bloque I - Recomendación\n",
        "\n",
        "Los esqueletos que se proporcionan a continuación son a modo de guía: el estudiante puede modificarlo todo libremente, siempre que la función **main_recsys** funcione correctamente **sin cambios**.\n",
        "\n",
        "Se implementarán estructuras y diferentes algoritmos para el desarrollo de sistemas de recomendación. \n",
        "\n",
        "**Importante**: recordar que no deben recomendarse los ítems que los usuarios ya hayan puntuado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        " Copyright (C) 2022 Pablo Castells, Alejandro Bellogín y Andrés Mena\n",
        "\n",
        " Este código se ha implementado para la realización de las prácticas de\n",
        " la asignatura \"Búsqueda y minería de información\" de 4º del Grado en\n",
        " Ingeniería Informática, impartido en la Escuela Politécnica Superior de\n",
        " la Universidad Autónoma de Madrid. El fin del mismo, así como su uso,\n",
        " se ciñe a las actividades docentes de dicha asignatura.\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "import heapq\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class Ranking:\n",
        "    class ScoredItem:\n",
        "        \"\"\"\n",
        "        Clase utilizada para gestionar las comparaciones que se realizan dentro del heap\n",
        "        \"\"\"\n",
        "        def __init__(self, element):\n",
        "            self.element = element\n",
        "\n",
        "        def __lt__(self, other):\n",
        "            \"\"\"\n",
        "            En primer lugar se compara el score. En caso de que sean iguales (mismo score),\n",
        "            se compara usando el itemid (se colocará más arriba el elemento con un itemid menor).\n",
        "            \"\"\"\n",
        "            return self.element[0] < other.element[0] if self.element[0] != other.element[0] \\\n",
        "                else self.element[1] > other.element[1]\n",
        "\n",
        "        def __eq__(self, other):\n",
        "            return self.element == other.element\n",
        "\n",
        "        def __str__(self):\n",
        "            return str(self.element)\n",
        "\n",
        "        def __repr__(self):\n",
        "            return self.__str__()\n",
        "\n",
        "    def __init__(self, topn):\n",
        "        self.heap = []\n",
        "        self.topn = topn\n",
        "        self.changed = 0\n",
        "\n",
        "    def add(self, item, score):\n",
        "        scored_item = self.ScoredItem((score, item))\n",
        "        if len(self.heap) < self.topn:\n",
        "            heapq.heappush(self.heap, scored_item)\n",
        "            self.changed = 1\n",
        "        elif scored_item > self.heap[0]:\n",
        "            heapq.heappop(self.heap)\n",
        "            heapq.heappush(self.heap, scored_item)\n",
        "            self.changed = 1\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.ranking = []\n",
        "        if self.changed:\n",
        "            h = self.heap.copy()\n",
        "            while h:\n",
        "                self.ranking.append(heapq.heappop(h).element[::-1])\n",
        "            self.changed = 0\n",
        "        return reversed(self.ranking)\n",
        "\n",
        "    def __repr__(self):\n",
        "        r = \"<\"\n",
        "        for item, score in self:\n",
        "            r = r + str(item) + \":\" + str(score) + \" \"\n",
        "        return r[0:-1] + \">\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicio 1: Estructuras de datos y recomendación simple (1pt)\n",
        "\n",
        "Implementar las clases necesarias para manejar **datos de entrada** (ratings) para los algoritmos de recomendación. La funcionalidad se implementará en una clase Ratings, que permitirá leer los datos de un fichero de texto, añadir ratings y acceder a ellos, así como un método que genere dos particiones aleatorias de entrenamiento y test, para evaluar y comparar la efectividad de diferentes algoritmos de recomendación. Nota: podéis asumir que los archivo de ratings no incluyen cabeceras.\n",
        "\n",
        "La **salida** de un recomendador consistirá en un diccionario con un ránking por usuario. Se facilita una clase Ranking basada en heap, similar a la utilizada para motores de búsqueda en la práctica anterior, para almacenar los ránkings de recomendación; la diferencia es que ahora no se devuelven ránkings en respuesta a consultas, sino un ránking por usuario de forma proactiva y en bloque para todos los usuarios presentes en el conjunto de ratings dado (sin que los usuarios lo \"pidan\" explícitamente).\n",
        "\n",
        "Implementar un primer **recomendador simple** por rating promedio en una clase `AverageRecommender`. El recomendador sólo recomendará ítems que tengan un mínimo de ratings, mínimo que se indicará como parámetro en el constructor (con ello se mejora el acierto de la recomendación). Se proporciona una clase `MajorityRecommender` a modo de ejemplo en el que el estudiante podrá basarse. También se proporciona `RandomRecommender`, que se utiliza en ocasiones como referencia en experimentos. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from math import sqrt\n",
        "\n",
        "class Ratings:\n",
        "    def __init__(self, file=\"\", delim='\\t', lines=None):\n",
        "        if file != \"\":\n",
        "            with open(file, \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "            # Crear un diccionario que, para cada usuario, guarde item y el rating = user[item: rating] #\n",
        "            # Crear diccionario para encontrar rating en funcion del item (funciones item e item_users) = item[user: rating] #\n",
        "        self.itemRatings, self.ratings = self.lines_to_dict(lines, delim)\n",
        "\n",
        "    def lines_to_dict(self, lines, delim='\\t'):\n",
        "        itemRatings = OrderedDict()\n",
        "        retings = OrderedDict()\n",
        "\n",
        "        for line in lines:\n",
        "            columns = line.split(delim)\n",
        "\n",
        "            user = int(columns[0])\n",
        "            item = int(columns[1])\n",
        "            rating = float(columns[2])\n",
        "\n",
        "            if user not in retings:\n",
        "                retings[user] = {}\n",
        "            if item not in retings[user]:\n",
        "                retings[user][item] = rating\n",
        "\n",
        "            if item not in itemRatings:\n",
        "                itemRatings[item] = {}\n",
        "            if user not in itemRatings[item]:\n",
        "                itemRatings[item][user] = rating\n",
        "\n",
        "        return  itemRatings, retings\n",
        "\n",
        "    def dict_to_lines(self, aux_dict):\n",
        "        lines = []\n",
        "        for user in aux_dict:\n",
        "            for item in aux_dict[user]:\n",
        "                rating = aux_dict[user][item]\n",
        "                lines.append(\"{}\\t{}\\t{}\".format(user, item, rating))\n",
        "        return lines\n",
        "\n",
        "    def rate(self, user, item, rating):\n",
        "        if user not in self.ratings:\n",
        "            self.ratings[user] = {}\n",
        "\n",
        "        if item not in self.ratings[user]:\n",
        "            self.ratings[user][item] = rating\n",
        "\n",
        "        if item not in self.itemRatings:\n",
        "            self.itemRatings[item] = {}\n",
        "\n",
        "        if user not in self.itemRatings[item]:\n",
        "            self.itemRatings[item][user] = rating\n",
        "\n",
        "    def rating(self, user, item):\n",
        "        try:\n",
        "            return self.ratings[user][item]\n",
        "        except KeyError:\n",
        "            return 0\n",
        "\n",
        "    # Ratio entre 0 y 1\n",
        "    def random_split(self, ratio, seed=None):\n",
        "        lines = self.dict_to_lines(self.ratings)\n",
        "\n",
        "        random.seed(seed)\n",
        "        random.shuffle(lines)\n",
        "\n",
        "        split = int(ratio * len(lines))\n",
        "\n",
        "        train = Ratings(lines=lines[:split])\n",
        "        test = Ratings(lines=lines[split:])\n",
        "\n",
        "        return train, test\n",
        "\n",
        "    def nratings(self):\n",
        "        n = 0\n",
        "\n",
        "        for user in self.ratings.keys():\n",
        "            for item in self.ratings[user]:\n",
        "                n += 1\n",
        "        return n\n",
        "\n",
        "    def users(self):\n",
        "        res = set()\n",
        "        for user in self.ratings.keys():\n",
        "            res.add(user)\n",
        "        return res\n",
        "\n",
        "    def items(self):\n",
        "        res = set()\n",
        "        for item in self.itemRatings.keys():\n",
        "            res.add(item)\n",
        "        return res\n",
        "\n",
        "    def user_items(self, user):\n",
        "        try:\n",
        "            return self.ratings[user]\n",
        "        except KeyError:\n",
        "            return []\n",
        "\n",
        "    def item_users(self, item):\n",
        "        try:\n",
        "            return self.itemRatings[item]\n",
        "        except KeyError:\n",
        "            return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Recommender(ABC):\n",
        "    def __init__(self, training):\n",
        "        self.training = training\n",
        "        self.recommendation = {}\n",
        "\n",
        "    def __repr__(self):\n",
        "        return type(self).__name__\n",
        "\n",
        "    @abstractmethod\n",
        "    def score(self, user, item):\n",
        "        \"\"\" Completar en otros recomenders \"\"\"\n",
        "\n",
        "    def recommend(self, topn):\n",
        "        for user in self.training.users():\n",
        "            ranking = Ranking(topn)\n",
        "\n",
        "            # Solo recomendar items que aun no tenga # \n",
        "            for item in self.training.items():\n",
        "                if item not in self.training.user_items(user):\n",
        "                    ranking.add(item, self.score(user, item))\n",
        "\n",
        "            self.recommendation[user] = ranking\n",
        "        return self.recommendation\n",
        "\n",
        "\n",
        "class RandomRecommender(Recommender):\n",
        "    def score(self, user, item):\n",
        "        return random.random()\n",
        "\n",
        "\n",
        "class MajorityRecommender(Recommender):\n",
        "    def __init__(self, ratings, threshold=0):\n",
        "        super().__init__(ratings)\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def score(self, user, item):\n",
        "        return sum(rating >= self.threshold for user, rating in self.training.item_users(item).items())\n",
        "\n",
        "\n",
        "class AverageRecommender(Recommender):\n",
        "    def __init__(self, ratings, minimo=0):\n",
        "        super().__init__(ratings)\n",
        "        self.minimo = minimo\n",
        "\n",
        "    def score(self, user, item):\n",
        "        \"\"\" Al indicarse el minimo por el constructor, se checkea que el numero de rankings llegue a ese minimo.\n",
        "        Por cada rating en user, se obtiene la suma del mismo y se divide entre el numero total de rankings, obteniendo asi la media \"\"\"\n",
        "\n",
        "        ratings = self.training.item_users(item).items()\n",
        "        if len(ratings) >= self.minimo:\n",
        "            return sum(rating for usesr, rating in ratings)/len(ratings)\n",
        "        else:\n",
        "            return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3YGEGm7haop"
      },
      "source": [
        "### Explicación/documentación\n",
        "\n",
        "Hay dos tipos de diccionarios: uno que guarda para cada usuario el rating de un item, es decir, en función del usuario, se guarda el item con el rating que le ha dado; el otro, que guarda para cada item, el usuario que lo ha valorado, por lo tanto de un item puedes sacar los usuarios que lo han valorado.\n",
        "Para crear el primero, se comprueba que el usuario no está ya en el diccionario y después si el item no ha sido valorado por el usuario se guarda, de tal forma que el usuario ha valorado ese item. Para el segundo, primero se comprueba que el item esté en el diccionario para después guardar el rating dependiendo de el usuario que lo valora.\n",
        "\n",
        "En la clase Recommender, hay tres formas de recomendar: Random, Majority y Average. El primero devolverá una recomendación aleatoria, el segundo devolverá la suma de los ratings de todos los items que hayan sido valorados por los usuarios; el último, devolverá la media del rating cuyo denominador será el número de items con valoraciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3ti8qGedgNB"
      },
      "source": [
        "## Ejercicio 2: Filtrado colaborativo kNN (3pt)\n",
        "\n",
        "Implementar dos variantes de filtrado colaborativo mediante vecinos próximos orientado a usuarios:\n",
        "\n",
        "* Implementar la clase `UserKNNRecommender` para realizar filtrado colaborativo **basado en usuario** por *similitud coseno* (sin normalizar por la suma de similitudes). Se sugiere crear los vecindarios \"offline\" en el constructor del recomendador. Se recomienda asimismo utilizar la clase `Ranking`, que utiliza un heap de ránking, para construir los vecindarios.\n",
        "* Implementar una variante normalizada `NormUserKNNRecommender`. De forma similar a la recomendación por rating promedio, el algoritmo exigirá un mínimo de ratings de vecinos para aceptar recomendar un ítem (con ello se mejora el acierto de la recomendación)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wzZ-6OG0dvwX"
      },
      "outputs": [],
      "source": [
        "from math import pow, sqrt\n",
        "\n",
        "class UserSimilarity(ABC):\n",
        "    @ abstractmethod\n",
        "    def sim(self, user1, user2):\n",
        "        \"\"\" Completado en otros UserSimilarity \"\"\"\n",
        "\n",
        "\n",
        "class CosineUserSimilarity(UserSimilarity):\n",
        "    def __init__(self, train):\n",
        "        self.train = train\n",
        "\n",
        "    def sim(self, user1, user2):\n",
        "        # SUM(items_u1 interseccion items_u2) #\n",
        "        total_sum = 0\n",
        "        for i in self.train.user_items(user1).keys():\n",
        "            if i in self.train.user_items(user2).keys():\n",
        "                total_sum += self.train.rating(user1, i) * self.train.rating(user2, i)\n",
        "\n",
        "        # Modulo de user1 #\n",
        "        m1 = 0\n",
        "        for i in self.train.user_items(user1).keys():\n",
        "            m1 += pow(self.train.rating(user1, i), 2)\n",
        "        m1 = sqrt(m1)\n",
        "\n",
        "        # Modulo de user2 #\n",
        "        m2 = 0\n",
        "        for i in self.train.user_items(user2).keys():\n",
        "            m2 += pow(self.train.rating(user2, i), 2)\n",
        "        m2 = sqrt(m2)\n",
        "\n",
        "        return total_sum / (m1 * m2)\n",
        "\n",
        "\n",
        "class UserKNNRecommender(Recommender):\n",
        "    def __init__(self, ratings, sim, k):\n",
        "        super().__init__(ratings)\n",
        "        self.sim = sim\n",
        "        self.k = k\n",
        "        self.dist = {}\n",
        "\n",
        "        all_users = set(self.training.users())\n",
        "        # Crear vecindarios de k vecinos mas cercanos\n",
        "        for user in self.training.users():\n",
        "            # Quitamos al propio usuario #\n",
        "            all_users.discard(user)\n",
        "            \n",
        "            # Si el usuario no está en el vecindario, lo introducimos en el vecindario con el ranking que tenga #\n",
        "            if user not in self.dist:\n",
        "                self.dist[user] = Ranking(k)\n",
        "\n",
        "            # Si cualquier otro usuario que pueda ser vecino no está, lo introducimos del mismo modo #\n",
        "            for other_user in all_users:\n",
        "                if other_user not in self.dist:\n",
        "                    self.dist[other_user] = Ranking(k)\n",
        "\n",
        "                # Caluclamos la similitud de coseno entre usuarios y guardamos la distancia #\n",
        "                similarity = sim.sim(user, other_user)\n",
        "                if similarity != 0.0:\n",
        "                    self.dist[user].add(other_user, similarity)\n",
        "                    self.dist[other_user].add(user, similarity)\n",
        "\n",
        "    def score(self, user, item):\n",
        "        total_sum = 0\n",
        "        for (other_user, distance) in self.dist[user]:\n",
        "            other_user_ratings = self.training.ratings[other_user]\n",
        "            if item in other_user_ratings.keys():\n",
        "                total_sum += distance * other_user_ratings[item]\n",
        "        return total_sum\n",
        "\n",
        "\n",
        "class NormUserKNNRecommender(UserKNNRecommender):\n",
        "    def __init__(self, ratings, sim, k, min):\n",
        "        super().__init__(ratings, sim, k)\n",
        "        self.minimo = min\n",
        "\n",
        "    def score(self, user, item):\n",
        "        total_sum = 0\n",
        "        den = 0\n",
        "        num_ratings = 0\n",
        "\n",
        "        \"\"\" NormUserKNN tiene en cuenta el numero de vecinos efectivos, por lo tanto el vecino \n",
        "        tiene que tener un ranking != 0, el numerador será la distancia del usuario a su vecino por\n",
        "        su rating mientras que el denominador será la suma de las distancias de los usuarios \"\"\"\n",
        "        for (other_user, distance) in self.dist[user]:\n",
        "            other_user_ratings = self.training.ratings[other_user]\n",
        "            if item in other_user_ratings.keys():\n",
        "                num_ratings += 1\n",
        "                total_sum += distance * other_user_ratings[item]\n",
        "                den += distance\n",
        "        if den == 0 or num_ratings < self.minimo:\n",
        "            return 0\n",
        "        return total_sum / den"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7xYd4hzhukr"
      },
      "source": [
        "### Explicación/documentación\n",
        "\n",
        "Para el UserKNNRecommender, se recogen todos los vecinos del usuario al que se hará la recomendación (sin introducir al propio usuario), y se calcula la similitud de cosenos entre usuarios. Para dar el score, solo habrá que iterar entre los items que hayan recibido una valoracion de un vecino del usuario e introducir el algoritmo knn.\n",
        "\n",
        "Para el NormUserKNNRecommender, habrá que hacer lo mismo excepto que el score no tendrá en cuenta las valoraciones de 0 (ya que no serían vecinos efectivos), y el numero total de valoraciones debe ser mayor a un minimo que se pase por parámetro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpXHr18Cdl2Q"
      },
      "source": [
        "## Ejercicio 3: Ampliación de algoritmos (1pt)\n",
        "\n",
        "Implementar dos variantes adicionales de los algoritmos de filtrado colaborativo y basados en contenido, tales como:\n",
        "\n",
        "* Un algoritmo colaborativo por **vecinos próximos orientado a ítem**. \n",
        "* **Otras variantes** adicionales a elección del estudiante, por ejemplo: similitud de Pearson, kNN centrado en la media. \n",
        "\n",
        "Para probar los métodos deberá completarse la función `student_test_recsys()` del apartado siguiente que ilustre la ejecución de las variantes adicionales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "MOfT2yZGpMNi"
      },
      "outputs": [],
      "source": [
        "class ItemNNRecommender(Recommender):\n",
        "    def __init__(self, ratings, sim, k):\n",
        "        super().__init__(ratings)\n",
        "        self.sim = sim\n",
        "        self.k = k\n",
        "        self.dist = {}\n",
        "\n",
        "        elementos = set(self.training.items())\n",
        "        # Crear vecindarios de k vecinos mas cercanos\n",
        "        for elemento in self.training.items():\n",
        "            elementos.discard(elemento)\n",
        "            if elemento not in self.dist:\n",
        "                self.dist[elemento] = Ranking(k)\n",
        "            for otro_elemento in elementos:\n",
        "                if otro_elemento not in self.dist:\n",
        "                    self.dist[otro_elemento] = Ranking(k)\n",
        "\n",
        "                similarity = sim.sim(elemento, otro_elemento)\n",
        "                if similarity != 0.0:\n",
        "                    self.dist[elemento].add(otro_elemento, similarity)\n",
        "                    self.dist[otro_elemento].add(elemento, similarity)\n",
        "\n",
        "    def score(self, user, item):\n",
        "        summation = 0\n",
        "        for (otro_elemento, distance) in self.dist[item]:\n",
        "            otro_elemento_ratings = self.training.ratings[otro_elemento]\n",
        "            if user in otro_elemento_ratings.keys():\n",
        "                summation += distance * otro_elemento_ratings[user]\n",
        "        return summation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJDzjUp-hwNZ"
      },
      "source": [
        "### Explicación/documentación\n",
        "\n",
        "ItemKNNRecommender sigue los mismos principios que UserKNNRecommender, salvo que en vez de estar orientado a usuarios está orientado a items. En este caso se cogen todos los items, se descarta el propio item, y se calcula la similitud de coseno entre los items vecinos. En cuanto al score, es obtener el rating del item y aplicar el algoritmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVzsIg0Zev7a"
      },
      "source": [
        "## Ejercicio 4: Evaluación (1pt)\n",
        "\n",
        "Se desarrollarán clases que permitan calcular métricas para evaluar y comparar el acierto de los recomendadores: se implementarán **precisión** y **recall**. \n",
        "\n",
        "Como resumen de este bloque, se incluirá una *tabla con los valores de las métricas* (dos columnas) más el tiempo de ejecución (una columna más) sobre todos los algoritmos implementados (filas), al menos para el conjunto de datos de <ins>ml-latest-small.zip</ins>.\n",
        "\n",
        "Opcionalmente, se podrán implementar otras métricas a elección del estudiante (nDCG, etc.), cuya prueba se incluirá en la función `student_test_recsys()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "VqSKneeSe2bN"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class EvaluationMetric(ABC):\n",
        "    def __init__(self, test, cutoff):\n",
        "        self.test = test\n",
        "        self.cutoff = cutoff\n",
        "\n",
        "    def __repr__(self):\n",
        "        return type(self).__name__ + (\"@\" + str(self.cutoff) if self.cutoff != math.inf else \"\")\n",
        "\n",
        "    def compute(self, recommendation):\n",
        "        \"\"\" Completar \"\"\"\n",
        "\n",
        "\n",
        "class Precision(EvaluationMetric):\n",
        "    def __init__(self, test, cutoff, threshold):\n",
        "        self.threshold = threshold\n",
        "        super().__init__(test, cutoff)\n",
        "\n",
        "    def compute(self, recommendation):\n",
        "        ret = 0\n",
        "\n",
        "        for user in recommendation.keys():\n",
        "            n = 0\n",
        "            relevantes = 0\n",
        "            for rec in recommendation[user]:\n",
        "                try:\n",
        "                    if self.test.rating(user, rec[0]) >= self.threshold:\n",
        "                        relevantes += 1\n",
        "                except:\n",
        "                    pass  # Si el usuario no está en test la métrica es 0\n",
        "                n += 1\n",
        "\n",
        "                if n == self.cutoff:\n",
        "                    break\n",
        "\n",
        "            p = relevantes / n\n",
        "            ret += p\n",
        "\n",
        "        return ret / len(recommendation.keys())\n",
        "\n",
        "\n",
        "class Recall(EvaluationMetric):\n",
        "    def __init__(self, test, cutoff, threshold):\n",
        "        self.threshold = threshold\n",
        "        super().__init__(test, cutoff)\n",
        "\n",
        "    def compute(self, recommendation):\n",
        "        ret = 0\n",
        "\n",
        "        for user in recommendation.keys():\n",
        "            n = 0\n",
        "            rel_Devueltos = 0\n",
        "            rel_Totales = 0\n",
        "\n",
        "            for rec in recommendation[user]:\n",
        "                try:\n",
        "                    if self.test.rating(user, rec[0]) >= self.threshold:\n",
        "                        rel_Devueltos += 1\n",
        "                except:\n",
        "                    pass\n",
        "                n += 1\n",
        "\n",
        "                if n == self.cutoff:\n",
        "                    break\n",
        "            try:\n",
        "                for item in self.test.user_items(user):\n",
        "                    if self.test.rating(user, item) >= self.threshold:\n",
        "                        rel_Totales += 1\n",
        "                r = rel_Devueltos / rel_Totales\n",
        "            except:\n",
        "                r = 0\n",
        "                pass\n",
        "\n",
        "            ret += r\n",
        "\n",
        "        return ret / len(recommendation.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def student_test_recsys(train, test, k, topn, cutoff):\n",
        "\n",
        "    recomendadores = [RandomRecommender(train), MajorityRecommender(train, threshold=topn), AverageRecommender(train, minimo=3), UserKNNRecommender(train, CosineUserSimilarity(train), k)]\n",
        "    metricas = [Precision(test, cutoff=cutoff, threshold=topn), Recall(test, cutoff=cutoff, threshold=topn)]\n",
        "\n",
        "    for recomendador in recomendadores:\n",
        "        print(\"Evaluating\", recomendador)\n",
        "        start = time.process_time()\n",
        "        recommendation = recomendador.recommend(5)\n",
        "        print(\"--> elapsed time:\", datetime.timedelta(seconds=round(time.process_time() - start)), \"<--\")\n",
        "        for metrica in metricas:\n",
        "            print(\"   \", metrica, \"=\", metrica.compute(recommendation))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucORmwfCh4Um"
      },
      "source": [
        "### Explicación/documentación\n",
        "\n",
        "El algoritmo Precision obtiene la interseccion de los documentos relevantes y los documentos que se han obtenido en total y divide el valor entre el numero total de documentos que se han obtenido.\n",
        "\n",
        "El algoritmo Recall obtiene la interseccion de los documentos relevantes y los documentos obtenidos en total (igual que precision), pero divide el resultado entre el numero de documentos relevantes.\n",
        "\n",
        "\n",
        "|      | Precision@4 | Recall@4 | Tiempo |\n",
        "| ----- | --------- | -------- | ----- |\n",
        "| RandomRecomender | 0.05 | 0.2 | 0:00:00 |\n",
        "| MajorityRecommender | 0.05 | 0.2 | 0:00:00 |\n",
        "| AverageRecommender | 0.05 | 0.2 | 0:00:00 |\n",
        "| UserKNNRecommender | 0.05 | 0.2 | 0:00:00 |\n",
        "\n",
        "\n",
        "|      | Precision@5 | Recall@5 | Tiempo |\n",
        "| ----- | --------- | -------- | ----- |\n",
        "| RandomRecomender | 0.0006557377049180328| 0.0005100182149362477 | 0:00:05 |\n",
        "| MajorityRecommender | 0.07180327868852462 | 0.08222516076149182 | 0:00:17 |\n",
        "| AverageRecommender | 0.0 | 0.0 | 0:00:14 |\n",
        "| UserKNNRecommender | 0.08819672131147552 | 0.11508790797101469 | 0:00:14 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Programa de prueba **main_recsys**\n",
        "\n",
        "Descarga los ficheros del curso de Moodle y coloca sus contenidos en una carpeta **recsys_data** en el mismo directorio que este *notebook*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================\n",
            "Toy test\n",
            "-------------------------\n",
            "Evaluating RandomRecommender\n",
            "    Precision@4 = 0.05\n",
            "    Recall@4 = 0.0\n",
            "Evaluating MajorityRecommender\n",
            "    Precision@4 = 0.05\n",
            "    Recall@4 = 0.0\n",
            "Evaluating AverageRecommender\n",
            "    Precision@4 = 0.1\n",
            "    Recall@4 = 0.0\n",
            "Evaluating UserKNNRecommender\n",
            "    Precision@4 = 0.15\n",
            "    Recall@4 = 0.0\n",
            "Evaluating NormUserKNNRecommender\n",
            "    Precision@4 = 0.15\n",
            "    Recall@4 = 0.0\n",
            "=========================\n",
            "Testing toy dataset\n",
            "-------------------------\n",
            "Testing the data structures\n",
            "22 ratings by 5 users on 10 items\n",
            "Ratings of user 1 : {1: 1.0, 5: 5.0, 7: 2.0, 10: 5.0}\n",
            "Ratings of item 2 : {2: 2.0, 4: 2.0}\n",
            "-------------------------\n",
            "Testing RandomRecommender (top 4)\n",
            "    User 1 -> <8:0.9731157639793706 3:0.8071282732743802 4:0.7297317866938179 2:0.6037260313668911>\n",
            "    User 2 -> <8:0.8617069003107772 3:0.8294046642529949 5:0.6185197523642461 10:0.577352145256762>\n",
            "    User 3 -> <2:0.7045718362149235 6:0.28938796360210717 8:0.23279088636103018 4:0.22789827565154686>\n",
            "    User 4 -> <3:0.6356844442644002 6:0.37018096711688264 5:0.36483217897008424 1:0.2779736031100921>\n",
            "Testing MajorityRecommender (top 4)\n",
            "    User 1 -> <3:1 4:1 6:1 9:1>\n",
            "    User 2 -> <5:2 1:1 3:1 10:1>\n",
            "    User 3 -> <3:1 4:1 6:1 7:1>\n",
            "    User 4 -> <5:2 1:1 3:1 6:1>\n",
            "Testing AverageRecommender (top 4)\n",
            "    User 1 -> <4:4.0 6:4.0 9:2.5 2:2.0>\n",
            "    User 2 -> <5:4.0 10:3.3333333333333335 1:2.6666666666666665 3:0>\n",
            "    User 3 -> <4:4.0 6:4.0 7:2.6666666666666665 9:2.5>\n",
            "    User 4 -> <5:4.0 6:4.0 1:2.6666666666666665 9:2.5>\n",
            "--> elapsed time: 0:00:00 <--\n",
            "Creating user cosine similarity\n",
            "--> elapsed time: 0:00:00 <--\n",
            "Creating kNN recommender\n",
            "--> elapsed time: 0:00:00 <--\n",
            "Testing UserKNNRecommender (top 4)\n",
            "    User 1 -> <2:1.0509735746180562 3:0 4:0 6:0>\n",
            "    User 2 -> <1:1.1446247360403807 3:0 5:0 8:0>\n",
            "    User 3 -> <2:0.28867513459481287 3:0 4:0 6:0>\n",
            "    User 4 -> <1:0.908212320458273 3:0 5:0 6:0>\n",
            "--> elapsed time: 0:00:00 <--\n",
            "Testing NormUserKNNRecommender (top 4)\n",
            "    User 1 -> <2:2.0 3:0 4:0 6:0>\n",
            "    User 2 -> <1:2.2386934925565565 3:0 5:0 8:0>\n",
            "    User 3 -> <2:0 3:0 4:0 6:0>\n",
            "    User 4 -> <1:1.911222747187516 3:0 5:0 6:0>\n",
            "--> elapsed time: 0:00:00 <--\n",
            "-------------------------\n",
            "Evaluating RandomRecommender\n",
            "    Precision@4 = 0.0\n",
            "    Recall@4 = 0.0\n",
            "Evaluating MajorityRecommender\n",
            "    Precision@4 = 0.0\n",
            "    Recall@4 = 0.0\n",
            "Evaluating AverageRecommender\n",
            "    Precision@4 = 0.05\n",
            "    Recall@4 = 0.0\n",
            "Evaluating UserKNNRecommender\n",
            "    Precision@4 = 0.0\n",
            "    Recall@4 = 0.0\n",
            "Evaluating NormUserKNNRecommender\n",
            "    Precision@4 = 0.0\n",
            "    Recall@4 = 0.0\n",
            "Evaluating RandomRecommender\n",
            "--> elapsed time: 0:00:00 <--\n",
            "    Precision@4 = 0.05\n",
            "    Recall@4 = 0.0\n",
            "Evaluating MajorityRecommender\n",
            "--> elapsed time: 0:00:00 <--\n",
            "    Precision@4 = 0.0\n",
            "    Recall@4 = 0.0\n",
            "Evaluating AverageRecommender\n",
            "--> elapsed time: 0:00:00 <--\n",
            "    Precision@4 = 0.0\n",
            "    Recall@4 = 0.0\n",
            "Evaluating UserKNNRecommender\n",
            "--> elapsed time: 0:00:00 <--\n",
            "    Precision@4 = 0.0\n",
            "    Recall@4 = 0.0\n",
            "=========================\n",
            "Testing MovieLens \"latest-small\" dataset\n",
            "-------------------------\n",
            "Testing the data structures\n",
            "100836 ratings by 610 users on 9724 items\n",
            "Ratings of user 35 : {11: 4.0, 21: 5.0, 39: 3.0, 50: 5.0, 60: 5.0, 62: 5.0, 150: 5.0, 185: 5.0, 222: 4.0, 231: 3.0, 235: 4.0, 236: 4.0, 237: 3.0, 252: 4.0, 261: 5.0, 266: 2.0, 300: 4.0, 316: 3.0, 339: 5.0, 342: 4.0, 590: 5.0, 592: 4.0, 595: 3.0}\n",
            "Ratings of item 1240 : {1: 5.0, 7: 5.0, 15: 4.0, 17: 5.0, 18: 4.0, 19: 4.0, 21: 3.5, 28: 4.5, 30: 3.5, 31: 4.0, 45: 3.0, 57: 4.0, 64: 3.5, 66: 4.0, 68: 4.0, 71: 4.0, 75: 4.0, 78: 5.0, 79: 4.0, 91: 4.5, 95: 5.0, 98: 1.0, 115: 5.0, 125: 4.0, 135: 5.0, 140: 3.0, 149: 4.0, 160: 4.0, 164: 5.0, 166: 3.0, 178: 4.5, 182: 2.0, 186: 4.0, 197: 4.0, 198: 3.0, 199: 5.0, 201: 5.0, 202: 4.0, 212: 4.0, 213: 4.0, 217: 2.0, 219: 4.0, 220: 4.5, 222: 3.5, 223: 3.0, 226: 4.0, 231: 4.0, 232: 4.5, 239: 4.0, 246: 4.5, 249: 4.0, 261: 4.0, 265: 5.0, 266: 4.0, 267: 5.0, 272: 4.0, 274: 4.0, 279: 4.0, 282: 4.5, 288: 3.0, 290: 4.0, 292: 4.0, 298: 4.0, 301: 0.5, 303: 5.0, 304: 5.0, 305: 3.5, 307: 2.5, 312: 4.0, 313: 5.0, 330: 2.5, 332: 4.0, 334: 3.5, 346: 2.5, 354: 4.0, 359: 2.5, 368: 4.0, 370: 4.0, 372: 3.0, 376: 4.0, 380: 5.0, 381: 2.5, 385: 4.0, 387: 4.0, 391: 4.0, 393: 0.5, 407: 3.0, 414: 5.0, 419: 3.5, 425: 3.0, 428: 2.5, 432: 3.5, 434: 3.5, 438: 4.0, 439: 4.0, 448: 3.0, 452: 5.0, 453: 4.0, 462: 4.0, 464: 4.0, 465: 4.0, 469: 4.0, 474: 4.0, 475: 4.5, 477: 4.0, 480: 4.0, 483: 3.5, 489: 3.5, 493: 4.0, 514: 4.0, 520: 4.0, 524: 4.0, 528: 4.0, 532: 4.0, 555: 5.0, 561: 4.0, 562: 5.0, 570: 3.5, 573: 4.5, 577: 4.0, 580: 3.5, 590: 4.5, 594: 5.0, 597: 4.0, 599: 3.5, 600: 3.0, 603: 4.0, 606: 4.0, 607: 5.0, 608: 3.5, 610: 5.0}\n",
            "-------------------------\n",
            "Testing RandomRecommender (top 5)\n",
            "    User 1 -> <173255:0.9997830435389712 2170:0.999754886941506 217:0.9997035524897339 3629:0.9995488705554942 2670:0.9994425438327824>\n",
            "    User 2 -> <77931:0.9997721525521609 152077:0.9997544395437363 3964:0.9997504086962059 8870:0.9997395526227271 1676:0.9996817260413083>\n",
            "    User 3 -> <8934:0.999931059275592 3306:0.9998846531248022 1323:0.9998071487798971 93272:0.9997435379673627 5959:0.999661735127912>\n",
            "    User 4 -> <48319:0.9999136345919298 29:0.9999072454724003 74789:0.9995786817481488 2337:0.9995407239173124 46231:0.9995405098571492>\n",
            "Testing MajorityRecommender (top 5)\n",
            "    User 1 -> <318:274 858:158 589:150 4993:146 7153:140>\n",
            "    User 2 -> <356:249 296:244 593:225 2571:222 260:201>\n",
            "    User 3 -> <318:274 356:249 296:244 593:225 2571:222>\n",
            "    User 4 -> <318:274 356:249 527:175 110:166 50:163>\n",
            "Testing AverageRecommender (top 5)\n",
            "    User 1 -> <6460:4.9 26810:4.833333333333333 115122:4.833333333333333 3224:4.75 7121:4.75>\n",
            "    User 2 -> <6460:4.9 26810:4.833333333333333 115122:4.833333333333333 3224:4.75 7121:4.75>\n",
            "    User 3 -> <6460:4.9 26810:4.833333333333333 115122:4.833333333333333 3224:4.75 7121:4.75>\n",
            "    User 4 -> <6460:4.9 26810:4.833333333333333 115122:4.833333333333333 3224:4.75 7121:4.75>\n",
            "--> elapsed time: 0:00:46 <--\n",
            "Creating user cosine similarity\n",
            "--> elapsed time: 0:00:00 <--\n",
            "Creating kNN recommender\n",
            "--> elapsed time: 0:00:26 <--\n",
            "Testing UserKNNRecommender (top 5)\n",
            "    User 1 -> <2:1.66357981982037 4:0 5:0 7:0 8:0>\n",
            "    User 2 -> <1:3.57065870072608 2:0 3:0 4:0 5:0>\n",
            "    User 3 -> <1:0.7521606943027179 2:0 3:0 4:0 5:0>\n",
            "    User 4 -> <1:10.183300088833498 2:0 3:0 4:0 5:0>\n",
            "--> elapsed time: 0:00:10 <--\n",
            "Testing NormUserKNNRecommender (top 5)\n",
            "    User 1 -> <2:0 4:0 5:0 7:0 8:0>\n",
            "    User 2 -> <1:3.543219586959323 2:0 3:0 4:0 5:0>\n",
            "    User 3 -> <1:4.0 2:0 3:0 4:0 5:0>\n",
            "    User 4 -> <1:4.087970554890852 2:0 3:0 4:0 5:0>\n",
            "--> elapsed time: 0:00:36 <--\n",
            "-------------------------\n",
            "Evaluating RandomRecommender\n",
            "    Precision@5 = 0.0009836065573770494\n",
            "    Recall@5 = 0.0\n",
            "Evaluating MajorityRecommender\n",
            "    Precision@5 = 0.1422950819672134\n",
            "    Recall@5 = 0.0\n",
            "Evaluating AverageRecommender\n",
            "    Precision@5 = 0.0019672131147540984\n",
            "    Recall@5 = 0.0\n",
            "Evaluating UserKNNRecommender\n",
            "    Precision@5 = 0.021967213114754077\n",
            "    Recall@5 = 0.0\n",
            "Evaluating NormUserKNNRecommender\n",
            "    Precision@5 = 0.021967213114754077\n",
            "    Recall@5 = 0.0\n",
            "Evaluating RandomRecommender\n",
            "--> elapsed time: 0:00:08 <--\n",
            "    Precision@5 = 0.0009836065573770494\n",
            "    Recall@5 = 0.0\n",
            "Evaluating MajorityRecommender\n",
            "--> elapsed time: 0:00:22 <--\n",
            "    Precision@5 = 0.06229508196721308\n",
            "    Recall@5 = 0.0\n",
            "Evaluating AverageRecommender\n",
            "--> elapsed time: 0:00:19 <--\n",
            "    Precision@5 = 0.0006557377049180328\n",
            "    Recall@5 = 0.0\n",
            "Evaluating UserKNNRecommender\n",
            "--> elapsed time: 0:00:10 <--\n",
            "    Precision@5 = 0.003934426229508197\n",
            "    Recall@5 = 0.0\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import time\n",
        "import itertools\n",
        "\n",
        "def main_recsys():\n",
        "    random.seed(42)\n",
        "    print(\"=========================\\nToy test\")\n",
        "    toy_test(\"recsys_data/toy\", '\\t')\n",
        "    print(\"=========================\\nTesting toy dataset\")\n",
        "    test_dataset(\"recsys_data/toy-ratings.dat\", 1, 2, k=4, min=2, topn=4, cutoff=4)\n",
        "    print(\"=========================\\nTesting MovieLens \\\"latest-small\\\" dataset\")\n",
        "    test_dataset(\"recsys_data/ratings.csv\", 35, 1240, k=10, min=3, topn=5, cutoff=5, delimiter=',')\n",
        "\n",
        "\n",
        "# First tests on toy dataset, using a pre-constructed data split\n",
        "def toy_test(dataset, separator='\\t'):\n",
        "    training = Ratings(dataset + \"-train.dat\", separator)\n",
        "    test = Ratings(dataset + \"-test.dat\", separator)\n",
        "    metrics = [Precision(test, cutoff=4, threshold=4), Recall(test, cutoff=4, threshold=4)]\n",
        "    evaluate_recommenders(training, metrics, k=4, min=2, topn=4)\n",
        "\n",
        "\n",
        "# More complete testing on a generic dataset\n",
        "def test_dataset(ratings_file, user, item, k, min, topn, cutoff, delimiter='\\t'):\n",
        "    ratings = Ratings(ratings_file, delimiter)\n",
        "    # Test Ratings class on the dataset\n",
        "    test_data(ratings, user, item)\n",
        "    # Run some recommenders on the entire rating data as input - no evaluation\n",
        "    test_recommenders(ratings, k, min, topn)\n",
        "    # Now produce a rating split to re-run the recommenders on the training data and evaluate them with the test data\n",
        "    train, test = ratings.random_split(0.8)\n",
        "    metrics = [Precision(test, cutoff, threshold=4), Recall(test, cutoff, threshold=4)]\n",
        "    evaluate_recommenders(train, metrics, k, min, 2 * topn)  # Double top n to test a slightly deeper ranking\n",
        "\n",
        "    # Additional testing?\n",
        "    student_test_recsys(train, test, k, topn, cutoff)\n",
        "\n",
        "\n",
        "# Test the rating data handling code (Ratings class)\n",
        "def test_data(ratings, user, item):\n",
        "    print(\"-------------------------\\nTesting the data structures\")\n",
        "    print(ratings.nratings(), \"ratings by\", len(ratings.users()), \"users on\", len(ratings.items()), \"items\")\n",
        "    print(\"Ratings of user\", user, \":\", ratings.user_items(user))\n",
        "    print(\"Ratings of item\", item, \":\", ratings.item_users(item))\n",
        "\n",
        "# Run some recommenders on the some rating data as input - no evaluation\n",
        "def test_recommenders(ratings, k, min, topn):\n",
        "    print(\"-------------------------\")\n",
        "    start = time.process_time()\n",
        "    test_recommender(RandomRecommender(ratings), topn)\n",
        "    test_recommender(MajorityRecommender(ratings, threshold=4), topn)\n",
        "    test_recommender(AverageRecommender(ratings, min), topn)\n",
        "    timer(start)\n",
        "    start = time.process_time()\n",
        "    print(\"Creating user cosine similarity\")\n",
        "    sim = CosineUserSimilarity(ratings)\n",
        "    timer(start)\n",
        "    start = time.process_time()\n",
        "    print(\"Creating kNN recommender\")\n",
        "    knn = UserKNNRecommender(ratings, sim, k)\n",
        "    timer(start)\n",
        "    start = time.process_time()\n",
        "    test_recommender(knn, topn)\n",
        "    timer(start)\n",
        "    start = time.process_time()\n",
        "    test_recommender(NormUserKNNRecommender(ratings, sim, k, min), topn)\n",
        "    timer(start)\n",
        "\n",
        "# Run one recommender on the some rating data as input - no evaluation\n",
        "def test_recommender(recommender, topn):\n",
        "    print(\"Testing\", recommender, \"(top\", str(topn) + \")\")\n",
        "    recommendation = recommender.recommend(topn)\n",
        "    for user in itertools.islice(recommendation, 4):\n",
        "        print(\"    User\", user, \"->\", recommendation[user])\n",
        "\n",
        "# Create some recommenders and send them for evaluation for a list of given metrics\n",
        "def evaluate_recommenders(training, metrics, k, min, topn):\n",
        "    print(\"-------------------------\")\n",
        "    start = time.process_time()\n",
        "    evaluate_recommender(RandomRecommender(training), topn, metrics)\n",
        "    evaluate_recommender(MajorityRecommender(training, threshold=4), topn, metrics)\n",
        "    evaluate_recommender(AverageRecommender(training, min), topn, metrics)\n",
        "    sim = CosineUserSimilarity(training)\n",
        "    knn = UserKNNRecommender(training, sim, k)\n",
        "    evaluate_recommender(knn, topn, metrics)\n",
        "    evaluate_recommender(NormUserKNNRecommender(training, sim, k, min), topn, metrics)\n",
        "\n",
        "# Run one recommender and evaluate a list of metrics on its output\n",
        "def evaluate_recommender(recommender, topn, metrics):\n",
        "    print(\"Evaluating\", recommender)\n",
        "    recommendation = recommender.recommend(topn)\n",
        "    for metric in metrics:\n",
        "        print(\"   \", metric, \"=\", metric.compute(recommendation))\n",
        "\n",
        "def timer(start):\n",
        "    print(\"--> elapsed time:\", datetime.timedelta(seconds=round(time.process_time() - start)), \"<--\")\n",
        "\n",
        "main_recsys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Salida obtenida por el estudiante\n",
        "\n",
        "#=========================\n",
        "Toy test\n",
        "#-------------------------\n",
        "Evaluating RandomRecommender\n",
        "    Precision@4 = 0.05\n",
        "    Recall@4 = 0.2\n",
        "Evaluating MajorityRecommender\n",
        "    Precision@4 = 0.05\n",
        "    Recall@4 = 0.2\n",
        "Evaluating AverageRecommender\n",
        "    Precision@4 = 0.1\n",
        "    Recall@4 = 0.4\n",
        "Evaluating UserKNNRecommender\n",
        "    Precision@4 = 0.1\n",
        "    Recall@4 = 0.4\n",
        "Evaluating NormUserKNNRecommender\n",
        "    Precision@4 = 0.15\n",
        "    Recall@4 = 0.6\n",
        "#=========================\n",
        "Testing toy dataset\n",
        "#-------------------------\n",
        "Testing the data structures\n",
        "22 ratings by 5 users on 10 items\n",
        "Ratings of user 1 : {1: 1.0, 5: 5.0, 7: 2.0, 10: 5.0}\n",
        "Ratings of item 2 : {2: 2.0, 4: 2.0}\n",
        "#-------------------------\n",
        "Testing RandomRecommender (top 4)\n",
        "    User 1 -> <8:0.9731157639793706 3:0.8071282732743802 4:0.7297317866938179 2:0.6037260313668911>\n",
        "    User 2 -> <8:0.8617069003107772 3:0.8294046642529949 5:0.6185197523642461 10:0.577352145256762>\n",
        "    User 3 -> <2:0.7045718362149235 6:0.28938796360210717 8:0.23279088636103018 4:0.22789827565154686>\n",
        "    User 4 -> <3:0.6356844442644002 6:0.37018096711688264 5:0.36483217897008424 1:0.2779736031100921>\n",
        "Testing MajorityRecommender (top 4)\n",
        "    User 1 -> <3:1 4:1 6:1 9:1>\n",
        "    User 2 -> <5:2 1:1 3:1 10:1>\n",
        "    User 3 -> <3:1 4:1 6:1 7:1>\n",
        "    User 4 -> <5:2 1:1 3:1 6:1>\n",
        "Testing AverageRecommender (top 4)\n",
        "    User 1 -> <4:4.0 6:4.0 9:2.5 2:2.0>\n",
        "    User 2 -> <5:4.0 10:3.3333333333333335 1:2.6666666666666665 3:0>\n",
        "    User 3 -> <4:4.0 6:4.0 7:2.6666666666666665 9:2.5>\n",
        "    User 4 -> <5:4.0 6:4.0 1:2.6666666666666665 9:2.5>\n",
        "--> elapsed time: 0:00:00 <--\n",
        "Creating user cosine similarity\n",
        "--> elapsed time: 0:00:00 <--\n",
        "Creating kNN recommender\n",
        "--> elapsed time: 0:00:00 <--\n",
        "Testing UserKNNRecommender (top 4)\n",
        "    User 1 -> <4:2.238184464464379 6:1.9851723076118835 9:1.3156632156329737 3:1.121038479592593>\n",
        "    User 2 -> <10:2.4731236802019043 5:1.9231236802019038 8:1.5000000000000004 3:1.2666666666666666>\n",
        "    User 3 -> <6:2.309401076758503 3:1.8475208614068024 9:1.8475208614068024 7:1.6725239222140886>\n",
        "    User 4 -> <5:2.2316605255328623 6:1.5000000000000004 1:0.908212320458273 9:0.5000000000000001>\n",
        "--> elapsed time: 0:00:00 <--\n",
        "Testing NormUserKNNRecommender (top 4)\n",
        "    User 1 -> <4:4.2592592592592595 6:4.1803278688524586 9:2.7704918032786883 2:2.0>\n",
        "    User 2 -> <5:3.7613065074434435 10:3.560373755618938 1:2.2386934925565565 3:0>\n",
        "    User 3 -> <7:1.841113295503649 2:0 3:0 4:0>\n",
        "    User 4 -> <5:4.696259084270828 1:1.911222747187516 3:0 6:0>\n",
        "--> elapsed time: 0:00:00 <--\n",
        "#-------------------------\n",
        "Evaluating RandomRecommender\n",
        "    Precision@4 = 0.0\n",
        "    Recall@4 = 0.0\n",
        "Evaluating MajorityRecommender\n",
        "    Precision@4 = 0.0\n",
        "    Recall@4 = 0.0\n",
        "Evaluating AverageRecommender\n",
        "    Precision@4 = 0.0\n",
        "    Recall@4 = 0.0\n",
        "Evaluating UserKNNRecommender\n",
        "    Precision@4 = 0.0\n",
        "    Recall@4 = 0.0\n",
        "Evaluating NormUserKNNRecommender\n",
        "    Precision@4 = 0.0\n",
        "    Recall@4 = 0.0\n",
        "Evaluating RandomRecommender\n",
        "    Precision@4 = 0.0\n",
        "    Recall@4 = 0.0\n",
        "Evaluating MajorityRecommender\n",
        "    Precision@4 = 0.0\n",
        "    Recall@4 = 0.0\n",
        "Evaluating AverageRecommender\n",
        "    Precision@4 = 0.0\n",
        "    Recall@4 = 0.0\n",
        "Evaluating UserKNNRecommender\n",
        "    Precision@4 = 0.0\n",
        "    Recall@4 = 0.0\n",
        "#=========================\n",
        "Testing MovieLens \"latest-small\" dataset\n",
        "#-------------------------\n",
        "Testing the data structures\n",
        "100836 ratings by 610 users on 9724 items\n",
        "Ratings of user 35 : {11: 4.0, 21: 5.0, 39: 3.0, 50: 5.0, 60: 5.0, 62: 5.0, 150: 5.0, 185: 5.0, 222: 4.0, 231: 3.0, 235: 4.0, 236: 4.0, 237: 3.0, 252: 4.0, 261: 5.0, 266: 2.0, 300: 4.0, 316: 3.0, 339: 5.0, 342: 4.0, 590: 5.0, 592: 4.0, 595: 3.0}\n",
        "Ratings of item 1240 : {1: 5.0, 7: 5.0, 15: 4.0, 17: 5.0, 18: 4.0, 19: 4.0, 21: 3.5, 28: 4.5, 30: 3.5, 31: 4.0, 45: 3.0, 57: 4.0, 64: 3.5, 66: 4.0, 68: 4.0, 71: 4.0, 75: 4.0, 78: 5.0, 79: 4.0, 91: 4.5, 95: 5.0, 98: 1.0, 115: 5.0, 125: 4.0, 135: 5.0, 140: 3.0, 149: 4.0, 160: 4.0, 164: 5.0, 166: 3.0, 178: 4.5, 182: 2.0, 186: 4.0, 197: 4.0, 198: 3.0, 199: 5.0, 201: 5.0, 202: 4.0, 212: 4.0, 213: 4.0, 217: 2.0, 219: 4.0, 220: 4.5, 222: 3.5, 223: 3.0, 226: 4.0, 231: 4.0, 232: 4.5, 239: 4.0, 246: 4.5, 249: 4.0, 261: 4.0, 265: 5.0, 266: 4.0, 267: 5.0, 272: 4.0, 274: 4.0, 279: 4.0, 282: 4.5, 288: 3.0, 290: 4.0, 292: 4.0, 298: 4.0, 301: 0.5, 303: 5.0, 304: 5.0, 305: 3.5, 307: 2.5, 312: 4.0, 313: 5.0, 330: 2.5, 332: 4.0, 334: 3.5, 346: 2.5, 354: 4.0, 359: 2.5, 368: 4.0, 370: 4.0, 372: 3.0, 376: 4.0, 380: 5.0, 381: 2.5, 385: 4.0, 387: 4.0, 391: 4.0, 393: 0.5, 407: 3.0, 414: 5.0, 419: 3.5, 425: 3.0, 428: 2.5, 432: 3.5, 434: 3.5, 438: 4.0, 439: 4.0, 448: 3.0, 452: 5.0, 453: 4.0, 462: 4.0, 464: 4.0, 465: 4.0, 469: 4.0, 474: 4.0, 475: 4.5, 477: 4.0, 480: 4.0, 483: 3.5, 489: 3.5, 493: 4.0, 514: 4.0, 520: 4.0, 524: 4.0, 528: 4.0, 532: 4.0, 555: 5.0, 561: 4.0, 562: 5.0, 570: 3.5, 573: 4.5, 577: 4.0, 580: 3.5, 590: 4.5, 594: 5.0, 597: 4.0, 599: 3.5, 600: 3.0, 603: 4.0, 606: 4.0, 607: 5.0, 608: 3.5, 610: 5.0}\n",
        "#-------------------------\n",
        "Testing RandomRecommender (top 5)\n",
        "    User 1 -> <5540:0.9999634808539639 56941:0.9999361757421015 3075:0.9998396704824943 595:0.99972327401748 168026:0.9996158100601125>\n",
        "    User 2 -> <574:0.9999585260956182 161127:0.9999183408022841 1300:0.9997905695756488 37240:0.9995628342595192 1344:0.9994958997671418>\n",
        "    User 3 -> <93297:0.9997714606780098 114180:0.9997658441203328 5980:0.9996220968629993 26701:0.9992004177274347 2244:0.999182275498943>\n",
        "    User 4 -> <2176:0.9999865047833005 4442:0.9999652805471292 172887:0.9997948142608275 61026:0.9997685494474438 110586:0.9996956742304444>\n",
        "Testing MajorityRecommender (top 5)\n",
        "    User 1 -> <318:274 858:158 589:150 4993:146 7153:140>\n",
        "    User 2 -> <356:249 296:244 593:225 2571:222 260:201>\n",
        "    User 3 -> <318:274 356:249 296:244 593:225 2571:222>\n",
        "    User 4 -> <318:274 356:249 527:175 110:166 50:163>\n",
        "Testing AverageRecommender (top 5)\n",
        "    User 1 -> <6460:4.9 26810:4.833333333333333 115122:4.833333333333333 3224:4.75 7121:4.75>\n",
        "    User 2 -> <6460:4.9 26810:4.833333333333333 115122:4.833333333333333 3224:4.75 7121:4.75>\n",
        "    User 3 -> <6460:4.9 26810:4.833333333333333 115122:4.833333333333333 3224:4.75 7121:4.75>\n",
        "    User 4 -> <6460:4.9 26810:4.833333333333333 115122:4.833333333333333 3224:4.75 7121:4.75>\n",
        "--> elapsed time: 0:00:33 <--\n",
        "Creating user cosine similarity\n",
        "--> elapsed time: 0:00:00 <--\n",
        "Creating kNN recommender\n",
        "--> elapsed time: 0:00:23 <--\n",
        "Testing UserKNNRecommender (top 5)\n",
        "    User 1 -> <589:14.182298865552864 1200:13.925161854229865 2762:13.422014858479724 1610:13.377867223000493 858:13.134549527466069>\n",
        "    User 2 -> <2959:7.8886254513902765 356:7.181835552316994 2571:7.106969059865804 33794:6.259884762412396 593:6.2012250262452095>\n",
        "    User 3 -> <1214:2.7575592777601163 1200:2.2072818953871876 1196:1.946306958245116 2858:1.9253209537004983 1198:1.903532023527017>\n",
        "    User 4 -> <858:13.097305785186183 1206:12.530262741570782 1193:11.363547457596145 1208:11.299206464803456 1222:11.006092453671277>\n",
        "--> elapsed time: 0:00:15 <--\n",
        "Testing NormUserKNNRecommender (top 5)\n",
        "    User 1 -> <1248:5.000000000000001 3108:5.0 1997:4.999999999999999 858:4.877534867861127 4993:4.875465244842439>\n",
        "    User 2 -> <48780:4.8418786629483845 4995:4.841592558601045 296:4.68141036849306 1193:4.61652970308254 1732:4.5028052159409615>\n",
        "    User 3 -> <3578:5.0 1215:4.999999999999999 50:4.88125745298354 47:4.842827449800377 1213:4.812480281563266>\n",
        "    User 4 -> <1104:5.0 1148:5.0 1256:5.0 1635:5.0 3022:5.0>\n",
        "--> elapsed time: 0:00:37 <--\n",
        "#-------------------------\n",
        "Evaluating RandomRecommender\n",
        "    Precision@5 = 0.0013114754098360656\n",
        "    Recall@5 = 0.0004626339052568561\n",
        "Evaluating MajorityRecommender\n",
        "    Precision@5 = 0.1557377049180332\n",
        "    Recall@5 = 0.06751278032799131\n",
        "Evaluating AverageRecommender\n",
        "    Precision@5 = 0.0006557377049180328\n",
        "    Recall@5 = 0.0005702066999287241\n",
        "Evaluating UserKNNRecommender\n",
        "    Precision@5 = 0.21278688524590236\n",
        "    Recall@5 = 0.11251095319177255\n",
        "Evaluating NormUserKNNRecommender\n",
        "    Precision@5 = 0.1265573770491808\n",
        "    Recall@5 = 0.07776971257284841\n",
        "Evaluating RandomRecommender\n",
        "    Precision@5 = 0.0003278688524590164\n",
        "    Recall@5 = 0.000819672131147541\n",
        "Evaluating MajorityRecommender\n",
        "    Precision@5 = 0.06885245901639347\n",
        "    Recall@5 = 0.06931171010040936\n",
        "Evaluating AverageRecommender\n",
        "    Precision@5 = 0.0003278688524590164\n",
        "    Recall@5 = 0.000819672131147541\n",
        "Evaluating UserKNNRecommender\n",
        "    Precision@5 = 0.09540983606557385\n",
        "    Recall@5 = 0.10617945377224677"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqbc9ng8e28p"
      },
      "source": [
        "# Bloque II - Análisis de redes sociales\n",
        "\n",
        "Los esqueletos que se proporcionan en este apartado son a modo de guía; el estudiante puede modificarlo todo libremente, siempre que la función **main_sna** funcione correctamente **sin cambios**.\n",
        "\n",
        "Para simplificar, en los ejercicios que siguen supondremos que las redes son no dirigidas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lOWgbqZpV01"
      },
      "source": [
        "## Ejercicio 5: Preliminares (2pt)\n",
        "\n",
        "Generar dos **redes sociales simuladas** siguiendo los modelos de Barabási-Albert y Erdös-Rényi. El tamaño y densidad de los grafos se deja a elección propia. Se puede utilizar para ello cualquier herramienta (como NetworkX ([documentación](https://networkx.org/documentation/stable/tutorial.html#graph-generators-and-graph-operations)), o el entorno interactivo de Gephi), o bien programar implementaciones propias (lo cual también es muy sencillo).\n",
        "\n",
        "Realizar un análisis básico de la **distribución del grado** en las siete redes sociales de la práctica: small x 3, Facebook, Twitter, Barabási-Albert y Erdös-Rényi. Para cada red:\n",
        "\n",
        "* Generar una gráfica de distribución del grado (utilizando escala log-log cuando ello sea útil) y comprobar en qué medida se observa una distribución power law.\n",
        "* Verificar si se observa la paradoja de la amistad (en sus diferentes versiones).\n",
        "\n",
        "Los resultados de este ejercicio no conllevan entrega de software, sino sólo la documentación de los mismos en el apartado de memoria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "br7yqFrnpZYl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\"\\nimport networkx\\nimport random\\nimport numpy\\nimport matplotlib.pyplot as mplot\\n\\nclass Barabasi(ABC):\\n    def __init__(self, initial_nodes, final_nodes, edges_per_node):\\n        self.initial_nodes = initial_nodes\\n        self.final_nodes = final_nodes\\n        self.edges_per_node = edges_per_node\\n\\n    def random_contact():\\n        contact_nodes = []\\n        for node in myGraph.nodes():\\n            grado = mygraph.degree(node)\\n\\n            node_prob = grado / (2 * len(mygraph.edges()))\\n            contact_nodes.append(node_prob)\\n\\n        return numpy.random.choice(myGraph.nodes(), p = node_prob)\\n\\n    def add_contact(self):\\n        if len(myGraph.edges()) == 0:\\n            random_cont = 0\\n        else:\\n            random_cont = random_contact()\\n\\n        new_contact = (random_cont, next_node)\\n\\n        if new_contact in myGraph.edges():\\n            add_contact()\\n\\n        else:\\n            myGraph.add_edge(next_node, random_cont)\\n\\n    def compute(self):\\n        myGraph = networkx.complete_graph(self.initial_nodes)\\n\\n        next_node = self.initial_nodes\\n        diff = 0\\n        for n in range(self.final_nodes - self.initial_nodes):\\n            myGraph.add_node(self.initial_nodes + diff)\\n            diff += 1\\n            for c in range(0, self.edges_per_node):\\n                add_contact()\\n            next_node += 1'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Si se ha realizado algún código, se puede incluir aquí\n",
        "# Si no se ha utilizado Python, se puede utilizar el apartado de explicación para describir el proceso y las herramientas utilizadas\n",
        "\n",
        "\n",
        "#import networkx\n",
        "#import random\n",
        "#import numpy\n",
        "#import matplotlib.pyplot as mplot\n",
        "\n",
        "\"\"\"class Barabasi(ABC):\n",
        "    def __init__(self, initial_nodes, final_nodes, edges_per_node):\n",
        "        self.initial_nodes = initial_nodes\n",
        "        self.final_nodes = final_nodes\n",
        "        self.edges_per_node = edges_per_node\n",
        "\n",
        "    def random_contact(self, myGraph):\n",
        "        contact_nodes = []\n",
        "        for node in myGraph.nodes():\n",
        "            grado = myGraph.degree(node)\n",
        "\n",
        "            node_prob = grado / (2 * len(myGraph.edges()))\n",
        "            contact_nodes.append(node_prob)\n",
        "\n",
        "        return numpy.random.choice(myGraph.nodes(), p = node_prob)\n",
        "\n",
        "    def add_contact(self, myGraph, next_node):\n",
        "        if len(myGraph.edges()) == 0:\n",
        "            random_cont = 0\n",
        "        else:\n",
        "            random_cont = random_contact(myGraph)\n",
        "\n",
        "        new_contact = (random_cont, next_node)\n",
        "\n",
        "        if new_contact in myGraph.edges():\n",
        "            add_contact(myGraph)\n",
        "\n",
        "        else:\n",
        "            myGraph.add_edge(next_node, random_cont)\n",
        "\n",
        "    def compute(self):\n",
        "        myGraph = networkx.complete_graph(self.initial_nodes)\n",
        "\n",
        "        next_node = self.initial_nodes\n",
        "        diff = 0\n",
        "        for n in range(self.final_nodes - self.initial_nodes):\n",
        "            myGraph.add_node(self.initial_nodes + diff)\n",
        "            diff += 1\n",
        "            for c in range(0, self.edges_per_node):\n",
        "                add_contact(myGraph, next_node)\n",
        "            next_node += 1\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzTje0viiM9I"
      },
      "source": [
        "### Explicación/documentación/imágenes generadas\n",
        "\n",
        "En este algoritmo de Barabasi-albert (nodos con preferencias) se establece una serie de nodos iniciales (que son los que estarían en u a habitación) y el número de nodos total que habrá, además del número de conexiones que realiza un nodo una vez entre al grafo (a la habitación).  Al ser un algoritmo preferente, los nodos que estén al principio en el grafo tendrán mayor grado que aquellos que entren después, aunque exite un factor aleatorio a la hora de hacer conexiones (función random_contact) y se irán haciendo vecinos en el grafo (función add_contacts). El algoritmo simplemente hará un loop e irá añadiendo nodos, y será la funcion add_contacts la que determine las conexiones de cada nodo. Si una conexión se repite, se vuelve a llamar a la funcion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcxuclLwpaM-"
      },
      "source": [
        "## Ejercicio 6: Métricas (2pt)\n",
        "\n",
        "Se implementarán las siguientes métricas topológicas *desde cero*:\n",
        "\n",
        "* Coeficiente de **clustering de un usuario**.\n",
        "* **Arraigo** de un arco (o de un par de usuarios).\n",
        "* Coeficiente de **clustering de una red social**.\n",
        "* Coeficiente de **asortatividad** de grado de una red."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "e3uq565SpfSA"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "import math\n",
        "import heapq\n",
        "\n",
        "class UndirectedSocialNetwork:\n",
        "    def __init__(self, file, delimiter='\\t', parse=0):\n",
        "        self.net = {}\n",
        "        self.edges = 0\n",
        "        f = open(file, \"r\")\n",
        "        lines = f.readlines()\n",
        "\n",
        "        \"\"\" Por cada linea conectamos los usuarios depediendo del parser que se introduzca\"\"\"\n",
        "        for line in lines:\n",
        "            u, v = line.split(delimiter)\n",
        "            if parse != 0:\n",
        "                u = parse(u)\n",
        "                v = parse(v)\n",
        "            else:\n",
        "                u = u.rstrip()\n",
        "                v = v.rstrip()\n",
        "\n",
        "            if u not in self.net:\n",
        "                self.net[u] = set()\n",
        "            if v not in self.net:\n",
        "                self.net[v] = set()\n",
        "            if u in self.net[v] and v in self.net[u]:\n",
        "                continue\n",
        "\n",
        "            self.net[u].add(v)\n",
        "            self.net[v].add(u)\n",
        "            self.edges += 1\n",
        "\n",
        "        f.close()\n",
        "\n",
        "    def users(self):\n",
        "        return list(self.net.keys())\n",
        "\n",
        "    def contacts(self, user):\n",
        "        return self.net[user]\n",
        "\n",
        "    def degree(self, user):\n",
        "        return len(self.net[user])\n",
        "\n",
        "    def add_contact(self, u, v):\n",
        "        if u not in self.net:\n",
        "            self.net[u] = set()\n",
        "        if v not in self.net:\n",
        "            self.sn[v] = set()\n",
        "\n",
        "        self.net[u].add(v)\n",
        "        self.net[v].add(u)\n",
        "        self.edges += 1\n",
        "\n",
        "    def connected(self, u, v):\n",
        "        if u in self.net[v] or v in self.net[u]:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def nedges(self):\n",
        "        return self.edges\n",
        "\n",
        "class Metric(ABC):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def __repr__(self):\n",
        "        return type(self).__name__ \n",
        "        \n",
        "    @abstractmethod\n",
        "    def compute_all(self, network):\n",
        "        \"\"\"\" Compute metric on all users or edges of network \"\"\"\n",
        "\n",
        "\n",
        "class LocalMetric(Metric):\n",
        "    def __init__(self, topn):\n",
        "        self.topn = topn\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute(self, network, element):\n",
        "        \"\"\"\" Compute metric on one user or edge of network \"\"\"\n",
        "\n",
        "class UserClusteringCoefficient(LocalMetric): # or LocalMetric? or other useful intermediate class?\n",
        "    def compute(self, network, element):\n",
        "        grado = network.degree(element)\n",
        "        \"\"\"Den = numero conexiones posibles total entre vecinos de i\"\"\"\n",
        "        den = (grado * (grado - 1)) / 2\n",
        "        if den == 0:\n",
        "            return 0\n",
        "        num = 0\n",
        "        \"\"\"Checkear si ls vecinos estan conectados y sumar si lo estan\"\"\"\n",
        "        vecinos = list(network.contacts(element))\n",
        "        for i in range(len(vecinos)):\n",
        "            for j in range(i + 1, len(vecinos)):\n",
        "                if vecinos[j] in network.contacts(vecinos[i]):\n",
        "                    num += 1\n",
        "        return num / den\n",
        "\n",
        "    def compute_all(self, network):\n",
        "        \"\"\"Devolver lo que tiene mas valor en la metrica en un ranking\"\"\"\n",
        "        rank = Ranking(self.topn)\n",
        "        for u in network.users():\n",
        "            score = self.compute(network, u)\n",
        "            rank.add(u, score)\n",
        "        return rank\n",
        "\n",
        "    def __repr__(self):\n",
        "        return type(self).__name__ + (\"@\" + str(self.topn) if self.topn != math.inf else \"\")\n",
        "\n",
        "class AvgUserMetric(Metric): # or LocalMetric? or other useful intermediate class?\n",
        "    def __init__(self, metric):\n",
        "        self.metric = metric\n",
        "\n",
        "    def compute_all(self, network):\n",
        "        ret = 0\n",
        "        for user in network.users():\n",
        "            ret += self.metric.compute(network, user)\n",
        "        return ret / len(network.users())\n",
        "    pass\n",
        "\n",
        "class Embeddedness(LocalMetric): # or LocalMetric? or other useful intermediate class?\n",
        "    \"\"\"Calcular los Jaccard\"\"\"\n",
        "    def compute(self, network, element):\n",
        "        interseccion = (network.contacts(element[0]) - set([element[1]])\n",
        "                 ) & (network.contacts(element[1]) - set([element[0]]))\n",
        "        union = (network.contacts(element[0]) - set([element[1]])\n",
        "                 ) | (network.contacts(element[1]) - set([element[0]]))\n",
        "\n",
        "        if len(union) == 0:\n",
        "            return 0\n",
        "\n",
        "        return len(interseccion) / len(union)\n",
        "\n",
        "    def compute_all(self, network):\n",
        "        rank = Ranking(self.topn)\n",
        "        newSet = set()\n",
        "        for u in network.users():\n",
        "            for v in network.users():\n",
        "                if v in newSet or v == u:\n",
        "                    continue\n",
        "                score = self.compute(network, (u, v))\n",
        "                rank.add((u, v), score)\n",
        "            newSet.add(u)\n",
        "        return rank\n",
        "\n",
        "    def __repr__(self):\n",
        "        return type(self).__name__ + (\"@\" + str(self.topn) if self.topn != math.inf else \"\")\n",
        "\n",
        "class ClusteringCoefficient(Metric): # or LocalMetric? or other useful intermediate class?\n",
        "    def compute_all(self, network):\n",
        "        triangulos = 0\n",
        "        tripletas = 0\n",
        "        \"\"\"Calcular el numero de tripletas y los triangulos que se forman.\n",
        "        El return sera la division de los triangulos por las tuplas.\n",
        "        Si se multiplica por 3 el numero de triangulos no da el valor esperado.\"\"\"\n",
        "        for u in network.users():\n",
        "            for v in network.contacts(u):\n",
        "                for x in network.contacts(v):\n",
        "                    if x == u:\n",
        "                        continue\n",
        "                    tripletas += 1\n",
        "                    if u in network.contacts(x):\n",
        "                        triangulos += 1\n",
        "\n",
        "        return triangulos / tripletas\n",
        "\n",
        "class Assortativity(Metric): # or LocalMetric? or other useful intermediate class?\n",
        "    def compute_all(self, network):\n",
        "        s1 = 0\n",
        "        s2 = 0\n",
        "        s3 = 0\n",
        "        metrica = set()\n",
        "        \"\"\"Calcular el valor total de la suma para cada usuario\"\"\"\n",
        "        for u in network.users():\n",
        "            for v in network.contacts(u):\n",
        "                if v in metrica:\n",
        "                    continue\n",
        "                s1 += network.degree(u) * network.degree(v)\n",
        "            metrica.add(u)\n",
        "            s2 += math.pow(network.degree(u), 2)\n",
        "            s3 += math.pow(network.degree(u), 3)\n",
        "\n",
        "        num_edges = network.nedges()\n",
        "        return (4 * num_edges * s1 - math.pow(s2, 2)) / (2 * num_edges * s3 - math.pow(s2, 2))\n",
        "\n",
        "class Ranking:\n",
        "    class ScoredUser:\n",
        "        \"\"\"\n",
        "        Clase utilizada para gestionar las comparaciones que se realizan dentro del heap\n",
        "        \"\"\"\n",
        "\n",
        "        def __init__(self, element):\n",
        "            self.element = element\n",
        "\n",
        "        def __lt__(self, other):\n",
        "            \"\"\"\n",
        "            En primer lugar se compara el score. En caso de que sean iguales (mismo score),\n",
        "            se compara usando el userid (se colocará más arriba el elemento con un userid menor).\n",
        "            \"\"\"\n",
        "            return self.element[0] < other.element[0] if self.element[0] != other.element[0] \\\n",
        "                else self.element[1] > other.element[1]\n",
        "\n",
        "        def __eq__(self, other):\n",
        "            return self.element == other.element\n",
        "\n",
        "        def __str__(self):\n",
        "            return str(self.element)\n",
        "\n",
        "        def __repr__(self):\n",
        "            return self.__str__()\n",
        "\n",
        "    def __init__(self, topn):\n",
        "        self.heap = []\n",
        "        self.topn = topn\n",
        "        self.changed = 0\n",
        "\n",
        "    def add(self, user, score):\n",
        "        scored_user = self.ScoredUser((score, user))\n",
        "        if len(self.heap) < self.topn:\n",
        "            heapq.heappush(self.heap, scored_user)\n",
        "            self.changed = 1\n",
        "        elif scored_user > self.heap[0]:\n",
        "            heapq.heappop(self.heap)\n",
        "            heapq.heappush(self.heap, scored_user)\n",
        "            self.changed = 1\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.changed:\n",
        "            self.ranking = []\n",
        "            h = self.heap.copy()\n",
        "            while h:\n",
        "                self.ranking.append(heapq.heappop(h).element[::-1])\n",
        "            self.changed = 0\n",
        "        return reversed(self.ranking)\n",
        "\n",
        "    def __repr__(self):\n",
        "        r = \"<\"\n",
        "        for user, score in self:\n",
        "            r += str(user) + \":\" + str(score) + \" \"\n",
        "        return r[0:-1] + \">\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d4hWTstiOIT"
      },
      "source": [
        "### Explicación/documentación\n",
        "\n",
        "Los algoritmos de métricas sociales se han hecho en función de los algoritmos que había en las diapositivas. Además, se ha creado una clase, ScoredUser, la cual tiene exactamente el mismo funcionamiento que la clase ScoredItem proporcionada al principio salvo que está orientada al usuario.\n",
        "\n",
        "Además, se documentarán en la memoria los tiempos de ejecución de las métricas en las redes de Facebook y Twitter, en una tabla con la siguiente estructura:\n",
        "\n",
        "|      | Facebook | Twitter |\n",
        "| ----- | -------- | ------ | \n",
        "| Coef. clustering usuario | 0:00:02 | 0:00:23 |\n",
        "| Embededness | 0:01:18 | 0:15:12 |\n",
        "| Coef. clustering global | 0:00:05 | 0:01:26 |\n",
        "| Asortatividad | 0:00:00 | 0:00:00 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPPWV7pepf85"
      },
      "source": [
        "## Ejercicio 7: Ejercicio libre (1pt)\n",
        "\n",
        "El estudiante desarrollará uno o varios métodos de análisis de redes a su propia elección. Se sugiere por ejemplo: \n",
        "\n",
        "* Implementación de métricas adicionales a elección del estudiante, tales como betweenness, closeness, distancia promedio, diámetro, modularidad, etc., integradas en la misma jerarquía de métricas que el ejercicio anterior.\n",
        "   - Para la modularidad, los colores de los nodos del grafo small3 sugieren una partición; consultar con el profesor si se desea probar con algún conjunto de datos público más.\n",
        "   - Si la métrica requiere usar el algoritmo de *shortest paths*, este no hace falta implementarlo, se puede usar el de alguna librería, como el disponible en [networkX](https://networkx.org/documentation/stable/reference/algorithms/shortest_paths.html)\n",
        "* Detección de comunidades y enlaces débiles.\n",
        "* Creación de modelos para la generación aleatoria de redes sociales (p.e. amigos de amigos, etc.).\n",
        "* Recomendación de contactos.\n",
        "\n",
        "Para este ejercicio deberá completarse la implementación de una función adicional `student_test_sna()` ilustrando la ejecución de las métricas y algoritmos implementados. \n",
        "\n",
        "El software que se desarrolle se incluirá en la entrega (en tantas celdas como se consideren oportuno), y se documentarán en la memoria las pruebas realizadas y los resultados obtenidos. En caso de que proceda mostrar figuras de grafos, se sugiere utilizar las facilidades de visualización de la herramienta Gephi.\n",
        "\n",
        "Este ejercicio se evaluará en base a la cantidad, calidad e interés del trabajo realizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "zg8MIMpipih1"
      },
      "outputs": [],
      "source": [
        "# Implementación o implementaciones elegidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def student_test_sna(data):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1gukouXiPV3"
      },
      "source": [
        "### Explicación/documentación\n",
        "\n",
        "(por hacer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zXhPtFzon72"
      },
      "source": [
        "## Programa de prueba **main_sna**\n",
        "\n",
        "Descarga los ficheros del curso de Moodle y coloca sus contenidos en una carpeta **graphs** en el mismo directorio que este *notebook*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "fTdDacCRn0u6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Testing graphs/small1.csv network\n",
            "12 users and 16 contact relationships\n",
            "User 6 has 4 contacts\n",
            "-------------------------\n",
            "UserClusteringCoefficient@5 : <1:1.0 2:1.0 3:1.0 7:1.0 9:1.0>\n",
            "UserClusteringCoefficient@5(6) = 0.3333333333333333\n",
            "--> elapsed time: 0:00:00 <--\n",
            "-------------------------\n",
            "Embeddedness@5 : <(3, 2):1.0 (9, 7):1.0 (12, 11):1.0 (1, 10):0.6666666666666666 (6, 8):0.6666666666666666>\n",
            "Embeddedness@5((6, 4)) = 0.16666666666666666\n",
            "--> elapsed time: 0:00:00 <--\n",
            "-------------------------\n",
            "ClusteringCoefficient = 0.5172413793103449\n",
            "--> elapsed time: 0:00:00 <--\n",
            "AvgUserMetric = 0.6666666666666666\n",
            "--> elapsed time: 0:00:00 <--\n",
            "Assortativity = -0.24271844660194175\n",
            "--> elapsed time: 0:00:00 <--\n",
            "==================================================\n",
            "Testing graphs/small2.csv network\n",
            "9 users and 16 contact relationships\n",
            "User 3 has 8 contacts\n",
            "-------------------------\n",
            "UserClusteringCoefficient@5 : <1:0.6666666666666666 2:0.6666666666666666 4:0.6666666666666666 5:0.6666666666666666 6:0.6666666666666666>\n",
            "UserClusteringCoefficient@5(3) = 0.2857142857142857\n",
            "--> elapsed time: 0:00:00 <--\n",
            "-------------------------\n",
            "Embeddedness@5 : <(1, 4):0.5 (1, 8):0.5 (2, 5):0.5 (4, 6):0.5 (6, 8):0.5>\n",
            "Embeddedness@5((3, 5)) = 0.2857142857142857\n",
            "--> elapsed time: 0:00:00 <--\n",
            "-------------------------\n",
            "ClusteringCoefficient = 0.46153846153846156\n",
            "--> elapsed time: 0:00:00 <--\n",
            "AvgUserMetric = 0.6243386243386244\n",
            "--> elapsed time: 0:00:00 <--\n",
            "Assortativity = -0.3333333333333333\n",
            "--> elapsed time: 0:00:00 <--\n",
            "==================================================\n",
            "Testing graphs/small3.csv network\n",
            "4 users and 5 contact relationships\n",
            "User a has 3 contacts\n",
            "-------------------------\n",
            "UserClusteringCoefficient@5 : <b:1.0 d:1.0 a:0.6666666666666666 c:0.6666666666666666>\n",
            "UserClusteringCoefficient@5(a) = 0.6666666666666666\n",
            "--> elapsed time: 0:00:00 <--\n",
            "-------------------------\n",
            "Embeddedness@5 : <('a', 'c'):1.0 ('b', 'd'):1.0 ('a', 'b'):0.5 ('a', 'd'):0.5 ('b', 'c'):0.5>\n",
            "Embeddedness@5(('a', 'b')) = 0.5\n",
            "--> elapsed time: 0:00:00 <--\n",
            "-------------------------\n",
            "ClusteringCoefficient = 0.75\n",
            "--> elapsed time: 0:00:00 <--\n",
            "AvgUserMetric = 0.8333333333333333\n",
            "--> elapsed time: 0:00:00 <--\n",
            "Assortativity = -0.6666666666666666\n",
            "--> elapsed time: 0:00:00 <--\n",
            "==================================================\n",
            "Testing graphs/twitter.csv network\n",
            "10029 users and 462399 contact relationships\n",
            "User el_pais has 1899 contacts\n",
            "-------------------------\n",
            "UserClusteringCoefficient@5 : <AlanaMurrin:1.0 AsFerreiro:1.0 AsTheyBurn:1.0 BJRatedR:1.0 BarrierMetal:1.0>\n",
            "UserClusteringCoefficient@5(el_pais) = 0.04107979852964596\n",
            "--> elapsed time: 0:00:23 <--\n",
            "-------------------------\n",
            "Embeddedness@5 : <('AffiliateMoney9', 'WebDeveloperCom'):1.0 ('AffiliateMoney9', 'onehunnidt'):1.0 ('Bako_Douche_Bag', 'Kriegsson'):1.0 ('DeafTechNews', 'mosesbillacura'):1.0 ('DeafTechNews', 'rtsuchi'):1.0>\n",
            "Embeddedness@5(('el_pais', 'ElviraLindo')) = 0.1581302834410741\n",
            "--> elapsed time: 0:15:12 <--\n",
            "-------------------------\n",
            "ClusteringCoefficient = 0.15427656957082322\n",
            "--> elapsed time: 0:01:26 <--\n",
            "AvgUserMetric = 0.2732379819086387\n",
            "--> elapsed time: 0:00:22 <--\n",
            "Assortativity = -0.07719727387408556\n",
            "--> elapsed time: 0:00:00 <--\n",
            "==================================================\n",
            "Testing graphs/facebook_combined.txt network\n",
            "4039 users and 88234 contact relationships\n",
            "User 9 has 57 contacts\n",
            "-------------------------\n",
            "UserClusteringCoefficient@5 : <32:1.0 33:1.0 35:1.0 42:1.0 44:1.0>\n",
            "UserClusteringCoefficient@5(9) = 0.39724310776942356\n",
            "--> elapsed time: 0:00:02 <--\n",
            "-------------------------\n",
            "Embeddedness@5 : <(4, 181):1.0 (4, 275):1.0 (6, 147):1.0 (8, 91):1.0 (8, 259):1.0>\n",
            "Embeddedness@5((9, 3)) = 0.22033898305084745\n",
            "--> elapsed time: 0:01:18 <--\n",
            "-------------------------\n",
            "ClusteringCoefficient = 0.5191742775433075\n",
            "--> elapsed time: 0:00:05 <--\n",
            "AvgUserMetric = 0.6055467186200876\n",
            "--> elapsed time: 0:00:02 <--\n",
            "Assortativity = 0.06357722918564918\n",
            "--> elapsed time: 0:00:00 <--\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import time\n",
        "\n",
        "def main_sna():\n",
        "    test_network(\"graphs/small1.csv\", \",\", 5, 6, 4, int)\n",
        "    test_network(\"graphs/small2.csv\", \",\", 5, 3, 5, int)\n",
        "    test_network(\"graphs/small3.csv\", \",\", 5, \"a\", \"b\")\n",
        "    test_network(\"graphs/twitter.csv\", \",\", 5, \"el_pais\", \"ElviraLindo\")\n",
        "    test_network(\"graphs/facebook_combined.txt\", \" \", 5, 9, 3, int)\n",
        "    # test_network(\"graphs/barabasi.csv\", \",\", 5, 1, 2, int) # uno de los grafos creados en Ejercicio 5\n",
        "    # test_network(\"graphs/erdos.csv\", \",\", 5, 1, 2, int) # el otro grafo creado en Ejercicio 5\n",
        "\n",
        "\n",
        "def test_network(file, delimiter, topn, u, v, parse=0):\n",
        "    print(\"==================================================\\nTesting \" + file + \" network\")\n",
        "    network = UndirectedSocialNetwork(file, delimiter=delimiter, parse=parse)\n",
        "    print(len(network.users()), \"users and\", network.nedges(), \"contact relationships\")\n",
        "    print(\"User\", u, \"has\", network.degree(u), \"contacts\")\n",
        "\n",
        "    # Métricas de usuarios\n",
        "    print(\"-------------------------\")\n",
        "    test_metric(UserClusteringCoefficient(topn), network, u)\n",
        "\n",
        "    # Métricas de arcos\n",
        "    print(\"-------------------------\")\n",
        "    test_metric(Embeddedness(topn), network, (u, v))\n",
        "\n",
        "    # Métricas globales de red\n",
        "    print(\"-------------------------\")\n",
        "    test_global_metric(ClusteringCoefficient(), network)\n",
        "    test_global_metric(AvgUserMetric(UserClusteringCoefficient(topn)), network)\n",
        "    test_global_metric(Assortativity(), network)\n",
        "\n",
        "    # Otros tests?\n",
        "    student_test_sna(network)\n",
        "\n",
        "\n",
        "def test_metric(metric, network, example):\n",
        "    start = time.process_time()\n",
        "    print(metric, \":\", metric.compute_all(network))\n",
        "    print(str(metric) + \"(\" + str(example) + \") =\", metric.compute(network, example))\n",
        "    timer2(start)\n",
        "\n",
        "\n",
        "def test_global_metric(metric, network):\n",
        "    start = time.process_time()\n",
        "    print(metric, \"=\", metric.compute_all(network))\n",
        "    timer2(start)\n",
        "\n",
        "\n",
        "def timer2(start):\n",
        "    print(\"--> elapsed time:\", datetime.timedelta(seconds=round(time.process_time() - start)), \"<--\")\n",
        "\n",
        "main_sna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5JhJJSFiSl5"
      },
      "source": [
        "### Salida obtenida por el estudiante\n",
        "\n",
        "==================================================\n",
        "Testing graphs/small1.csv network\n",
        "12 users and 16 contact relationships\n",
        "User 6 has 4 contacts\n",
        "-------------------------\n",
        "UserClusteringCoefficient@5 : <1:1.0 2:1.0 3:1.0 7:1.0 9:1.0>\n",
        "UserClusteringCoefficient@5(6) = 0.3333333333333333\n",
        "--> elapsed time: 0:00:00 <--\n",
        "-------------------------\n",
        "Embeddedness@5 : <(3, 2):1.0 (9, 7):1.0 (12, 11):1.0 (1, 10):0.6666666666666666 (6, 8):0.6666666666666666>\n",
        "Embeddedness@5((6, 4)) = 0.16666666666666666\n",
        "--> elapsed time: 0:00:00 <--\n",
        "-------------------------\n",
        "ClusteringCoefficient = 0.5172413793103449\n",
        "--> elapsed time: 0:00:00 <--\n",
        "AvgUserMetric = 0.6666666666666666\n",
        "--> elapsed time: 0:00:00 <--\n",
        "Assortativity = -0.24271844660194175\n",
        "--> elapsed time: 0:00:00 <--\n",
        "==================================================\n",
        "Testing graphs/small2.csv network\n",
        "9 users and 16 contact relationships\n",
        "User 3 has 8 contacts\n",
        "-------------------------\n",
        "UserClusteringCoefficient@5 : <1:0.6666666666666666 2:0.6666666666666666 4:0.6666666666666666 5:0.6666666666666666 6:0.6666666666666666>\n",
        "UserClusteringCoefficient@5(3) = 0.2857142857142857\n",
        "--> elapsed time: 0:00:00 <--\n",
        "-------------------------\n",
        "Embeddedness@5 : <(1, 4):0.5 (1, 8):0.5 (2, 5):0.5 (4, 6):0.5 (6, 8):0.5>\n",
        "Embeddedness@5((3, 5)) = 0.2857142857142857\n",
        "--> elapsed time: 0:00:00 <--\n",
        "-------------------------\n",
        "ClusteringCoefficient = 0.46153846153846156\n",
        "--> elapsed time: 0:00:00 <--\n",
        "AvgUserMetric = 0.6243386243386244\n",
        "--> elapsed time: 0:00:00 <--\n",
        "Assortativity = -0.3333333333333333\n",
        "--> elapsed time: 0:00:00 <--\n",
        "==================================================\n",
        "Testing graphs/small3.csv network\n",
        "4 users and 5 contact relationships\n",
        "User a has 3 contacts\n",
        "-------------------------\n",
        "UserClusteringCoefficient@5 : <b:1.0 d:1.0 a:0.6666666666666666 c:0.6666666666666666>\n",
        "UserClusteringCoefficient@5(a) = 0.6666666666666666\n",
        "--> elapsed time: 0:00:00 <--\n",
        "-------------------------\n",
        "Embeddedness@5 : <('a', 'c'):1.0 ('b', 'd'):1.0 ('a', 'b'):0.5 ('a', 'd'):0.5 ('b', 'c'):0.5>\n",
        "Embeddedness@5(('a', 'b')) = 0.5\n",
        "--> elapsed time: 0:00:00 <--\n",
        "-------------------------\n",
        "ClusteringCoefficient = 0.75\n",
        "--> elapsed time: 0:00:00 <--\n",
        "AvgUserMetric = 0.8333333333333333\n",
        "--> elapsed time: 0:00:00 <--\n",
        "Assortativity = -0.6666666666666666\n",
        "--> elapsed time: 0:00:00 <--\n",
        "==================================================\n",
        "Testing graphs/twitter.csv network\n",
        "10029 users and 462399 contact relationships\n",
        "User el_pais has 1899 contacts\n",
        "-------------------------\n",
        "UserClusteringCoefficient@5 : <AlanaMurrin:1.0 AsFerreiro:1.0 AsTheyBurn:1.0 BJRatedR:1.0 BarrierMetal:1.0>\n",
        "UserClusteringCoefficient@5(el_pais) = 0.04107979852964596\n",
        "--> elapsed time: 0:00:23 <--\n",
        "-------------------------\n",
        "Embeddedness@5 : <('AffiliateMoney9', 'WebDeveloperCom'):1.0 ('AffiliateMoney9', 'onehunnidt'):1.0 ('Bako_Douche_Bag', 'Kriegsson'):1.0 ('DeafTechNews', 'mosesbillacura'):1.0 ('DeafTechNews', 'rtsuchi'):1.0>\n",
        "Embeddedness@5(('el_pais', 'ElviraLindo')) = 0.1581302834410741\n",
        "--> elapsed time: 0:15:12 <--\n",
        "-------------------------\n",
        "ClusteringCoefficient = 0.15427656957082322\n",
        "--> elapsed time: 0:01:26 <--\n",
        "AvgUserMetric = 0.2732379819086387\n",
        "--> elapsed time: 0:00:22 <--\n",
        "Assortativity = -0.07719727387408556\n",
        "--> elapsed time: 0:00:00 <--\n",
        "==================================================\n",
        "Testing graphs/facebook_combined.txt network\n",
        "4039 users and 88234 contact relationships\n",
        "User 9 has 57 contacts\n",
        "-------------------------\n",
        "UserClusteringCoefficient@5 : <32:1.0 33:1.0 35:1.0 42:1.0 44:1.0>\n",
        "UserClusteringCoefficient@5(9) = 0.39724310776942356\n",
        "--> elapsed time: 0:00:02 <--\n",
        "-------------------------\n",
        "Embeddedness@5 : <(4, 181):1.0 (4, 275):1.0 (6, 147):1.0 (8, 91):1.0 (8, 259):1.0>\n",
        "Embeddedness@5((9, 3)) = 0.22033898305084745\n",
        "--> elapsed time: 0:01:18 <--\n",
        "-------------------------\n",
        "ClusteringCoefficient = 0.5191742775433075\n",
        "--> elapsed time: 0:00:05 <--\n",
        "AvgUserMetric = 0.6055467186200876\n",
        "--> elapsed time: 0:00:02 <--\n",
        "Assortativity = 0.06357722918564918\n",
        "--> elapsed time: 0:00:00 <--\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Enunciado P2",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
